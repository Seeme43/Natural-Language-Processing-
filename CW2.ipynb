{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center style=\"color:maroon\"> <h1> Part II NLP Coursework 1 </h1> </center>\n",
    "<center> <h3> Sentiment classifier for movie reviews from the BBC archive of film reviews </h3> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GOAL: develop a sentiment classifier for movie reviews trained on a DIY corpus built from the BBC archive of film reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import nltk\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "from nltk.classify import scikitlearn\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from nltk import word_tokenize\n",
    "import operator\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='maroon'> <h2> 1. Obtaining the Corpus </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **goal** of this section is the one of **obtaining the corpus**, composed by the list of reviews  for each movie and the grade, which goes from 1 to 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ Movies are ordered alphabetically + a page for movies which starts with a digit ]\n",
    "# OBTAIN A LIST WITH LINKS (link_az) . Each link is the page containing movies for the specific initial letter.\n",
    "\n",
    "# 1. Get list of letters and '0-9'\n",
    "a_z = [chr(i) for i in range(ord('a'),ord('z')+1)] # stackoverflow.com/questions/16060899/alphabet-range-python\n",
    "a_z.append('0-9')\n",
    "\n",
    "# 2. Get the list of link_az\n",
    "link_az = []\n",
    "for x in a_z:\n",
    "    link =  'http://www.bbc.co.uk/films/gateways/az/review/cinema/'+str(x)+ '.shtml'\n",
    "    link_az.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The page for each link leads to the movie review, through a new link.\n",
    "# So, I Obtain a new list (all_links) with all links to be used for scraping the reviews\n",
    "\n",
    "all_links = []\n",
    "for link in link_az:\n",
    "    url = link\n",
    "    html = request.urlopen(url).read().decode('utf8')\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    for i in soup.findAll('a'):          # Would be better to narrow the analysis in the div class = 'content' portion\n",
    "        all_links.append(i.get('href')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overcome the issue of having not only links of the review, but every link found in the page\n",
    "\n",
    "all_links = [link for link in all_links if link is not None ]    # avoid the None value\n",
    "all_links = [link for link in all_links if link.startswith('/films/')]   # all useful link start with this string\n",
    "all_links = [link for link in all_links if link[7].isdigit()]   # only the useful link have this characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get the review, in the later scraping \n",
    "def get_review(soup):\n",
    "    review = []\n",
    "    for p in soup.findAll(\"div\", {\"class\": \"content\"}):\n",
    "        review.append(p.text)\n",
    "        return(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get the score for each review, when scraping\n",
    "def get_score(soup):\n",
    "    score = []\n",
    "    for td in soup.find_all('td', 'film-ratings'):\n",
    "        for img in td.find_all('img', alt=True):\n",
    "            score.append((img['alt'][0]))\n",
    "            return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05758595d41d4504ae13191c9dedd036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3591), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scrape the review and their label \n",
    "\n",
    "links = all_links[:] # Prepare this line in order to eventually modify the size later\n",
    "reviews = []\n",
    "scores = []\n",
    "for link in tqdm(links):\n",
    "    try:\n",
    "        url = 'http://www.bbc.co.uk' + str(link)\n",
    "        html = request.urlopen(url).read().decode('utf8')\n",
    "        soup = BeautifulSoup(html,'lxml')\n",
    "        r = get_review(soup)\n",
    "        s = get_score(soup)\n",
    "        reviews.append(r)\n",
    "        scores.append(s)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the collection of reviews and scores into a dataframe\n",
    "\n",
    "df = pd.DataFrame({'rev' : reviews ,\n",
    "                  'sc' : scores},\n",
    "                  columns=['rev','sc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate None/Nan values\n",
    "df = df.replace(to_replace=[None], value = np.nan)\n",
    "df = df.dropna(axis=0, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have few issues:\n",
    "# 1. Need to convert each review in a string\n",
    "# 2. Need to remove the escape sequence\n",
    "\n",
    "review = []          \n",
    "for i in df.rev:\n",
    "    a = re.sub(r'<.*?>' ,'', i[0])\n",
    "    a = a.split('\\n')\n",
    "    a = ''.join(a).strip()\n",
    "    review.append(a)\n",
    "    \n",
    "df['review'] = review\n",
    "df = df.drop(['rev'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trasform the Score variable to 'int' variables\n",
    "\n",
    "score = []\n",
    "for x in df.sc:\n",
    "    b = x[0]\n",
    "    score.append(b)\n",
    "    \n",
    "df['score'] = score\n",
    "df = df.drop(['sc'], axis = 1)\n",
    "df['score'] = df.score.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the label sentiment with pos and neg, and label = 0 for values = 3.\n",
    "# In this way, I can eventually drop this label if the output pos and neg are unbalanced.\n",
    "\n",
    "sentiment = []\n",
    "for x in df.score:\n",
    "    if x > 3:\n",
    "        a = 'pos'\n",
    "        sentiment.append(a)\n",
    "    elif x < 3:\n",
    "        a = 'neg'\n",
    "        sentiment.append(a)\n",
    "    else:\n",
    "        a = 0 # this is going to be dropped to balance the output\n",
    "        sentiment.append(a)\n",
    "        \n",
    "df['sentiment'] = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    1168\n",
       "neg     965\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the balance between pos and neg\n",
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Balance the dataset \n",
    "df = df[df.sentiment != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset in order to avoid re-running all the code in case of failure of my kernel\n",
    "df.to_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='maroon'> <h2> 2. Prepare the Corpus for the Sentiment Analysis </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset obtained \n",
    "df = pd.read_csv('reviews.csv')\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2133"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain a list of tuples containing the words per review and the score \n",
    "documents = [(word_tokenize(review), cat) for review, cat in zip(df.review,df.sentiment)]\n",
    "random.shuffle(documents)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a list containing all the tokenized reviews\n",
    "rev_words = []\n",
    "for r in df.review:\n",
    "    res = word_tokenize(r)\n",
    "    rev_words.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unnest the nested list ( http://book.pythontips.com/en/latest/map_filter.html )\n",
    "rev_words = reduce(operator.add, rev_words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 32940, ',': 32797, '.': 19657, 'a': 19478, 'of': 17566, 'and': 16014, 'to': 13758, \"'s\": 11772, 'in': 9993, 'is': 9849, ...})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequency distribution of all the words included in the rev_words list \n",
    "all_words = nltk.FreqDist(w.lower() for w in rev_words)\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of the x most common words included in the all_words list\n",
    "# In this case, x = 500\n",
    "word_features = [w for (w,ct) in all_words.most_common(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document): \n",
    "    document_words = set(document) \n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2133"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train and Test\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='maroon'> <h2> 3. Apply ML classifier  </font> \n",
    "    \n",
    "The following section aims to lead the analysis by applying different classifiers:\n",
    "\n",
    "- Naive Bayes\n",
    "- Decision Tree\n",
    "- Multinomial Naive Bayes\n",
    "- Bernoulli Naive Bayes\n",
    "- Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "DT_classifier = nltk.DecisionTreeClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial NB\n",
    "classifierMNB = SklearnClassifier(MultinomialNB())\n",
    "classifierMNB.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bernoulli NB\n",
    "classifierBNB=SklearnClassifier(BernoulliNB())\n",
    "classifierBNB.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonezanetti/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression \n",
    "classifierLR = SklearnClassifier(LogisticRegression())\n",
    "classifierLR.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: 0.626\n",
      "Multinomial NB: 0.78\n",
      "Bernoulli NB: 0.768\n",
      "Logistic Regression: 0.758\n",
      "Naive Bayes: 0.77\n"
     ]
    }
   ],
   "source": [
    "print('Decision Tree:', nltk.classify.accuracy(DT_classifier, test_set))\n",
    "print('Multinomial NB:',nltk.classify.accuracy( classifierMNB,test_set))\n",
    "print('Bernoulli NB:',nltk.classify.accuracy(classifierBNB, test_set))\n",
    "print('Logistic Regression:', nltk.classify.accuracy(classifierLR,test_set))\n",
    "print('Naive Bayes:', nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      " contains(unfortunately) = True              neg : pos    =      6.6 : 1.0\n",
      "        contains(moving) = True              pos : neg    =      6.6 : 1.0\n",
      "         contains(sadly) = True              neg : pos    =      4.7 : 1.0\n",
      "   contains(documentary) = True              pos : neg    =      3.2 : 1.0\n",
      "        contains(review) = True              pos : neg    =      3.1 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check most informative words for Naive Bayes\n",
    "print(classifier.show_most_informative_features(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='maroon'> <h2> 4. Attempts to improve accuracy  </font> \n",
    "    \n",
    "In the following section I will perform different attempts in order to improve the accuracy.\n",
    "\n",
    "**NOTE:** Regression Tree will not be tested anymore, due to excessive sloweness of the evaluation of the code. Moreover, its accuracy seems to be the weakest so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a- Remove Punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a list containing all the tokenized reviews\n",
    "\n",
    "rev_words = []\n",
    "for r in df.review:\n",
    "    res = re.findall(r'\\w+', r)\n",
    "    rev_words.append(res)\n",
    "\n",
    "# Unnest the nested list ( http://book.pythontips.com/en/latest/map_filter.html )\n",
    "rev_words = reduce(operator.add, rev_words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 33737, 'a': 19644, 'of': 17666, 'and': 16153, 'to': 13863, 's': 11978, 'in': 10522, 'is': 9611, 'with': 6229, 'it': 5848, ...})"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequency distribution of all the words included in the rev_words list \n",
    "all_words = nltk.FreqDist(w.lower() for w in rev_words)\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of the x most common words included in the all_words list\n",
    "# In this case, x = 3000\n",
    "word_features = [w for (w,ct) in all_words.most_common(3000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Feature sets\n",
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "# Split Train and Test\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to test all the model quicker\n",
    "\n",
    "def tryall_models():\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set) # Naive Bayes\n",
    "    classifierMNB = SklearnClassifier(MultinomialNB()) # Multinomial NB\n",
    "    classifierMNB.train(train_set)\n",
    "    classifierBNB=SklearnClassifier(BernoulliNB()) # Bernoulli NB\n",
    "    classifierBNB.train(train_set)\n",
    "    classifierLR = SklearnClassifier(LogisticRegression()) #Logistic Regression \n",
    "    classifierLR.train(train_set)\n",
    "    \n",
    "    print('Multinomial NB:',nltk.classify.accuracy( classifierMNB,test_set))\n",
    "    print('Bernoulli NB:',nltk.classify.accuracy(classifierBNB, test_set))\n",
    "    print('Logistic Regression:', nltk.classify.accuracy(classifierLR,test_set))\n",
    "    print('Naive Bayes:', nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonezanetti/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB: 0.844\n",
      "Bernoulli NB: 0.842\n",
      "Logistic Regression: 0.836\n",
      "Naive Bayes: 0.844\n"
     ]
    }
   ],
   "source": [
    "tryall_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b- Vary the size of the Feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function with number of feature sets as parameter\n",
    "\n",
    "def attempts(numb):\n",
    "    word_features = [w for (w,ct) in all_words.most_common(numb)]\n",
    "    \n",
    "    def document_features(document): \n",
    "        document_words = set(document) \n",
    "        features = {}\n",
    "        for word in word_features:\n",
    "            features['contains({})'.format(word)] = (word in document_words)\n",
    "        return features\n",
    "    \n",
    "    featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "    global train_set,test_set\n",
    "    train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a943aa8bda0e413ca77e8ea26f26598c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt with 1000 Common words:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonezanetti/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB: 0.786\n",
      "Bernoulli NB: 0.798\n",
      "Logistic Regression: 0.764\n",
      "Naive Bayes: 0.798\n",
      "\n",
      "\n",
      "\n",
      "Attempt with 2000 Common words:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonezanetti/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB: 0.82\n",
      "Bernoulli NB: 0.82\n",
      "Logistic Regression: 0.828\n",
      "Naive Bayes: 0.818\n",
      "\n",
      "\n",
      "\n",
      "Attempt with 3000 Common words:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonezanetti/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB: 0.844\n",
      "Bernoulli NB: 0.842\n",
      "Logistic Regression: 0.836\n",
      "Naive Bayes: 0.844\n",
      "\n",
      "\n",
      "\n",
      "Attempt with 4000 Common words:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonezanetti/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB: 0.848\n",
      "Bernoulli NB: 0.848\n",
      "Logistic Regression: 0.842\n",
      "Naive Bayes: 0.854\n",
      "\n",
      "\n",
      "\n",
      "Attempt with 5000 Common words:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonezanetti/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB: 0.848\n",
      "Bernoulli NB: 0.854\n",
      "Logistic Regression: 0.834\n",
      "Naive Bayes: 0.848\n",
      "\n",
      "\n",
      "\n",
      "Attempt with 6000 Common words:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonezanetti/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB: 0.852\n",
      "Bernoulli NB: 0.856\n",
      "Logistic Regression: 0.842\n",
      "Naive Bayes: 0.854\n",
      "\n",
      "\n",
      "\n",
      "Attempt with 7000 Common words:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonezanetti/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB: 0.852\n",
      "Bernoulli NB: 0.866\n",
      "Logistic Regression: 0.842\n",
      "Naive Bayes: 0.854\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in tqdm(range(1000,8000, 1000)):\n",
    "    attempts(x)\n",
    "    print('Attempt with',x,'Common words:')\n",
    "    tryall_models()\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--> The size to be chosen is 6000/7000  <--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Eliminate stopwords from the set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With stopwords the feature size will change.\n",
    "# Define a function to attempt the different sizes of the feature sets out of the stopwords\n",
    "\n",
    "def attempts_stopwords(numb):\n",
    "    stop = stopwords.words('english')\n",
    "    word_features = [w for (w,ct) in all_words.most_common(numb)]\n",
    "    for word in word_features:\n",
    "        if word in stop:\n",
    "            word_features.remove(word)\n",
    "    \n",
    "    \n",
    "    def document_features(document): \n",
    "        document_words = set(document) \n",
    "        features = {}\n",
    "        for word in word_features:\n",
    "            features['contains({})'.format(word)] = (word in document_words)\n",
    "        return features\n",
    "    \n",
    "    featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "    global train_set,test_set\n",
    "    train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf26522ac4d494f9b4ad49208f823a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with 2000 most common words =  0.816\n",
      "accuracy with 3000 most common words =  0.84\n",
      "accuracy with 4000 most common words =  0.852\n",
      "accuracy with 5000 most common words =  0.842\n",
      "accuracy with 6000 most common words =  0.848\n"
     ]
    }
   ],
   "source": [
    "for x in tqdm(range(2000,8000, 1000)):\n",
    "    attempts_stopwords(x)\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "    print('accuracy with',x,'most common words = ', nltk.classify.accuracy(classifier, test_set))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582e55d9fe15406ba8cf9c641598709b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with 4000 most common words =  0.856\n",
      "accuracy with 5000 most common words =  0.84\n",
      "accuracy with 6000 most common words =  0.846\n",
      "accuracy with 7000 most common words =  0.852\n",
      "accuracy with 8000 most common words =  0.862\n",
      "accuracy with 9000 most common words =  0.86\n",
      "accuracy with 10000 most common words =  0.854\n",
      "accuracy with 11000 most common words =  0.85\n"
     ]
    }
   ],
   "source": [
    "for x in tqdm(range(4000,12000, 1000)):\n",
    "    attempts_stopwords(x)\n",
    "    classifierBNB=SklearnClassifier(BernoulliNB())\n",
    "    classifierBNB.train(train_set)\n",
    "    print('accuracy with',x,'most common words = ', nltk.classify.accuracy(classifierBNB, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Modify the size of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words lower than 7\n",
    "word = [w for (w,ct) in all_words.most_common(7000)]\n",
    "word_features = []\n",
    "for word in word:\n",
    "    if len(word) < 7:\n",
    "        word_features.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "global train_set,test_set\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB: 0.82\n"
     ]
    }
   ],
   "source": [
    "classifierBNB=SklearnClassifier(BernoulliNB())\n",
    "classifierBNB.train(train_set)\n",
    "print('Bernoulli NB:',nltk.classify.accuracy(classifierBNB, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher than 4\n",
    "word = [w for (w,ct) in all_words.most_common(7000)]\n",
    "word_features = []\n",
    "for word in word:\n",
    "    if len(word) > 3:\n",
    "        word_features.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "global train_set,test_set\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.856"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "       contains(unfunny) = True              neg : pos    =     22.1 : 1.0\n",
      "       contains(creates) = True              pos : neg    =     17.9 : 1.0\n",
      "      contains(physical) = True              pos : neg    =     17.3 : 1.0\n",
      "     contains(affecting) = True              pos : neg    =     13.1 : 1.0\n",
      "  contains(unconvincing) = True              neg : pos    =     12.9 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(classifier.show_most_informative_features(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB: 0.856\n"
     ]
    }
   ],
   "source": [
    "classifierBNB=SklearnClassifier(BernoulliNB())\n",
    "classifierBNB.train(train_set)\n",
    "print('Bernoulli NB:',nltk.classify.accuracy(classifierBNB, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
